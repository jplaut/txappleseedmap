{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes Texas Education Agency data about school district demographics and disciplinary actions, and puts them together in one GeoJSON file for the Texas Appleseed \"School to Prison Pipeline\" map. See http://www.texasdisciplinelab.org/\n",
    "\n",
    "To use the script, follow these instructions:\n",
    "\n",
    "1. For every year that you want to cover, download all 20 of the region files from http://rptsvr1.tea.texas.gov/adhocrpt/Disciplinary_Data_Products/Download_Region_Districts.html and put them in the directory '../data/from_agency/by_region/'\n",
    "\n",
    "2. For every year that you want to cover, download the \"District and Charter Detail Data\" Snapshot Data File (comma-delimited *.dat)\" from https://rptsvr1.tea.texas.gov/perfreport/snapshot/download.html. The website automatically delivers these files with the same filename: district.dat. You will need to rename them to have different names by adding the year after \"district\". For instance, \"district2016.dat\"\n",
    "\n",
    "3. This script needs a GeoJSON file of district shapes. Make sure it can find that file at '../geojson/base_districts.geojson'\n",
    "\n",
    "4. Change the first_year and last_year variables below to reflect the years you want your file to cover.\n",
    "\n",
    "5. Run the notebook with \"Kernel -> Restart and Run All\"\n",
    "\n",
    "6. Wait a while for it to finish. After about 15 minutes, the notebook should produce 'districts_with_data.geojson' in the '../geojson/' directory.\n",
    "\n",
    "7. The resulting file will be about 20 MB depending on how many years it covers. You can make it smaller (about 10 MB) by uploading it to http://mapshaper.org/, using the \"simplify\" function to reduce the number of lines in the district boundaries, and exporting the file as TopoJSON instead of GeoJSON. I did this and put the result in the '../topojson/' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "first_year = 2006 # the year 2006 is the first year on the TEA site\n",
    "last_year = 2016\n",
    "\n",
    "\n",
    "def formatDF(apple, year_col):\n",
    "    \n",
    "    # Removes rows and columns not needed for the map\n",
    "    \n",
    "    apple = apple.drop([\"AGGREGATION LEVEL\",\"REGION\",\"DISTNAME\"], axis = 1)\n",
    "    \n",
    "    # Adding totals for each discipline in each district, by adding up actions \n",
    "    # against special ed students and non-special ed students. This will be \n",
    "    # inefficient because it makes a dict list first instead of staying in pandas.\n",
    "    \n",
    "    non_special = {\"D06\": (\"D05\",\"D-EXPULSION ACTIONS\"), \n",
    "                   \"D09\": (\"D08\",\"E-DAEP PLACEMENTS\"), \n",
    "                   \"D12\": (\"D11\", \"F-OUT OF SCHOOL SUSPENSIONS\"), \n",
    "                   \"D15\": (\"D14\", \"G-IN SCHOOL SUSPENSIONS\")}\n",
    "    \n",
    "    all_actions = []\n",
    "    \n",
    "    # if it was a .csv, the headers would be [\"DISTRICT\", \"SECTION\", \"HEADING\", \"HEADING NAME\", year_col]\n",
    "    \n",
    "    unfound = []\n",
    "    \n",
    "    for d in apple.index.get_level_values(0).unique():\n",
    "        for key in non_special:\n",
    "            try: \n",
    "                a = apple.loc[(d, key)][year_col]\n",
    "            except KeyError:\n",
    "                a = 0\n",
    "            try:\n",
    "                b = apple.loc[(d, non_special[key][0])][year_col]\n",
    "            except KeyError:\n",
    "                b = 0\n",
    "            if a < 0: # in case of dummy values like -999\n",
    "                a = 1\n",
    "            if b < 0:\n",
    "                b = 1\n",
    "            total = a + b\n",
    "            all_actions.append({\"DISTRICT\": d, \"HEADING\": key, \"SECTION\": non_special[key][1], \n",
    "                                \"HEADING NAME\": \"ALL\", year_col: total})\n",
    "    \n",
    "    new = pd.DataFrame(all_actions)\n",
    "    new = new.set_index([\"DISTRICT\", \"HEADING\"])\n",
    "\n",
    "    # Keeping only the rows that categorize students by protected class.\n",
    "    \n",
    "    patternIn = 'WHITE|BLACK OR AFRICAN AMERICAN|AMERICAN INDIAN OR ALASKA NAT|HISPANIC|NATIVE HAWAIIAN|ASIAN|TWO OR MORE RACES|SPEC. ED|ECO. DISAD|ECO DISAD.|TOTAL'\n",
    "    apple = apple[apple[\"HEADING NAME\"].str.contains(patternIn)]\n",
    "    \n",
    "    # Getting rid of rows that count students instead of incidents, or non-disadvantaged kids.\n",
    "    \n",
    "    patternOut = 'SPEC. ED. STUDENTS| SPEC. ED. EXPULSIONS TO JJAEP|ECO DISAD. STUDENTS|ECO. DISAD. STUDENTS|AT RISK|NON AT|UNKNOWN AT|NON SPEC. ED.|NON ECO DISAD.|NON ECO. DISAD.'\n",
    "    apple = apple[apple[\"HEADING NAME\"].str.contains(patternOut) == False]\n",
    "\n",
    "    # Delete rows appearing to double-count the same expulsions.\n",
    "    \n",
    "    JJAEPReplace = {\"SECTION\": {\n",
    "                        'M-ECO\\. DISADV\\. JJAEP PLACEMENTS|H-SPEC\\. ED\\. JJAEP EXPULSIONS': 'C-JJAEP EXPULSIONS'}}\n",
    "    apple = apple.replace(to_replace=JJAEPReplace, regex=True)\n",
    "    apple = apple[apple[\"SECTION\"].str.contains(\"JJAEP EXPULSIONS|DISCIPLINE ACTION COUNTS\") == False]\n",
    "                    \n",
    "    apple = apple.append(new)\n",
    "    \n",
    "    # Consolidating some of the descriptors into broader categories\n",
    "    \n",
    "    appleReplace = {year_col:\n",
    "                        {-99999999: 1, -999999: 1, -999: 1},\n",
    "                    \"SECTION\": {\n",
    "                        'D-EXPULSION ACTIONS|N-ECO\\. DISADV\\. EXPULSIONS|I-SPEC\\. ED\\. EXPULSIONS': 'EXP',\n",
    "                        'E-DAEP PLACEMENTS|O-ECO\\. DISADV\\. DAEP PLACEMENTS|J-SPEC\\. ED\\. DAEP PLACEMENTS': 'DAE',\n",
    "                        'F-OUT OF SCHOOL SUSPENSIONS|P-ECO\\. DISADV\\. OUT OF SCHOOL SUS.|K-SPEC\\. ED\\. OUT OF SCHOOL SUS\\.': 'OSS',\n",
    "                        'G-IN SCHOOL SUSPENSIONS|Q-ECO\\. DISADV\\. IN SCHOOL SUS\\.|L-SPEC\\. ED\\. IN SCHOOL SUS\\.': 'ISS'},\n",
    "                    \"HEADING NAME\": {'SPEC\\. ED.*$': 'SPE',\n",
    "                                     'ECO?. DISAD.*$': 'ECO',\n",
    "                                     'HISPANIC': 'HIS',\n",
    "                                     'HIS/LATINO': 'HIS',\n",
    "                                     'HISPANIC/LATINO': 'HIS',\n",
    "                                     'BLACK OR AFRICAN AMERICAN': 'BLA',\n",
    "                                     'BLACK/AFRICAN AMERICAN': 'BLA',\n",
    "                                     'WHITE': 'WHI',\n",
    "                                     'AMERICAN INDIAN OR ALASKA NAT': 'IND',\n",
    "                                     'ASIAN': 'ASI',\n",
    "                                     'NATIVE HAWAIIAN/OTHER PACIFIC': 'PCI',\n",
    "                                     'TWO OR MORE RACES': 'TWO',\n",
    "                                    }\n",
    "                    }\n",
    "\n",
    "    apple = apple.replace(to_replace=appleReplace, regex=True)\n",
    "    \n",
    "    return apple\n",
    "\n",
    "def getYear(year):\n",
    "    year_col = \"YR{}\".format(str(year)[-2:])\n",
    "    apple_path = '../data/from_agency/by_region/REGION_{}_DISTRICT_summary_{}.csv'\n",
    "    one_year = [pd.read_csv(apple_path.format(str(region).zfill(2),str(year)[-2:]), \n",
    "                            index_col = [\"DISTRICT\",\"HEADING\"], dtype = {year_col: int})\n",
    "                for region in range(1,21)]\n",
    "    a = pd.concat(one_year)\n",
    "    \n",
    "    # a = a.set_index([\"DISTRICT\",\"HEADING\"] )\n",
    "    a = a[~a.index.duplicated(keep='last')]  # a single row was causing a non-unique multiindex error \n",
    "    # print(a.loc[31901])\n",
    "    a = formatDF(a, year_col)\n",
    "    \n",
    "        # the path to the files in the district demographics directory\n",
    "    districtPath = '../data/from_agency/districts/district{}.dat'.format(year)\n",
    "    district = populations(districtPath)\n",
    "\n",
    "    statewide_students_count = district[\"DPETALLC\"].sum()\n",
    "\n",
    "    apple = a.reset_index()\n",
    "    appleAll = apple[apple[\"HEADING NAME\"] == \"ALL\"].rename({year_col: \"all_punishments\"}, axis = 1).drop([\"HEADING NAME\", \"HEADING\"], axis = 1)\n",
    "    print(appleAll[:5])\n",
    "    apple = apple.merge(district, how = \"left\", left_on = \"DISTRICT\", right_index = True)\n",
    "    \n",
    "    apple = apple[apple[\"DPETALLC\"].notnull()]\n",
    "    \n",
    "    punishment_totals = {}\n",
    "    for p in apple[\"SECTION\"].unique():\n",
    "        punishment_totals[p] = apple[apple[\"SECTION\"] == p][apple[\"HEADING NAME\"] == \"ALL\"][year_col].sum()\n",
    "        \n",
    "    # apple[18464:18470]  previous problem rows, gone because of the .notnull()\n",
    "    \n",
    "    apple = apple.merge(appleAll, how = \"left\", left_on = [\"DISTRICT\",\"SECTION\"], right_on = [\"DISTRICT\",\"SECTION\"])\n",
    "    \n",
    "    \"\"\"    \n",
    "    # This line will run slowly because for each row, it searches the entire dataframe\n",
    "    apple[\"all_punishments\"] = apple.apply(lambda x: \n",
    "                                               apple[apple[\"DISTRICT\"] == x[\"DISTRICT\"]][apple[\"SECTION\"] == x[\"SECTION\"]][apple[\"HEADING NAME\"] == \"ALL\"][year_col].values[0], axis=1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # New column will show the district's percentage of the state's student population.\n",
    "    district[\"DPETALLP\"] = district.apply(lambda x: x[\"DPETALLC\"] / statewide_students_count * 100, axis=1).round(2)\n",
    "    \n",
    "    apple[\"LikelyError\"] = apple.apply(lambda x: getLE(x, year_col), axis=1)\n",
    "    apple[\"Scale\"] = apple.apply(lambda x: getScale(x, year_col, punishment_totals, statewide_students_count), axis=1)\n",
    "    apple[\"Percentage\"] = apple.apply(lambda x: getPercentage(x, year_col, punishment_totals), axis=1).round(3)\n",
    "    \n",
    "    apple[\"Year\"] = year\n",
    "    \n",
    "    # apple = apple.set_index([\"DISTRICT\",\"SECTION\",\"HEADING NAME\", \"Year\"])\n",
    "    # apple = apple.sort_index() # trying to improve speed\n",
    "    \n",
    "    return apple[\"DISTRICT\",\"SECTION\",\"HEADING NAME\", \"Year\", \"LikelyError\", \"Percentage\", \"Scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populations(districtPath):\n",
    "    district = pd.read_csv(districtPath, index_col=\"DISTRICT\")\n",
    "\n",
    "    district = district.rename(columns = {\"SNAPDIST\": 'DISTNAME'})\n",
    "    \n",
    "    sometimes_missing = [ 'DPETINDP', 'DPETASIP', 'DPETPCIP', 'DPETTWOP']\n",
    "    \n",
    "    for c in sometimes_missing:\n",
    "        if c not in district.columns:\n",
    "            district[c] = np.nan\n",
    "    \n",
    "    # deleting redundant columns\n",
    "    \n",
    "    district = district[['DISTNAME', 'REGION', 'DPETALLC', \n",
    "                         'DPETBLAP', 'DPETHISP', 'DPETWHIP', 'DPETINDP',\n",
    "                         'DPETASIP', 'DPETPCIP', 'DPETTWOP', 'DPETECOP', \n",
    "                         'DPETSPEP']] # 'DISTRICT' not listed because it's the index\n",
    "\n",
    "    return district\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getRatio(distPop, racePop, all_punishments, group_punishments):\n",
    "    # Calculating ratio of punishments for the demographic group compared to the punishments for the student population\n",
    "    # as a whole. For instance, \"0.505\" in the disparity column indicates the group got the punishment 50.5% as often\n",
    "    # as average for the student population.\n",
    "\n",
    "    \"\"\"\n",
    "    >>> getRatio(200, 20, 20, 10)\n",
    "    4.0\n",
    "    >>> getRatio(200, 20, 20, 2)\n",
    "    0.0\n",
    "    >>> print(getRatio(200, 0, 20, 0))\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    if max(racePop, group_punishments) == 0 or None:\n",
    "        return None\n",
    "    elif all_punishments == 0 or None:\n",
    "        return 0\n",
    "    else:\n",
    "        disparity = (group_punishments / (max(all_punishments, group_punishments))\n",
    "                     / (max(racePop, group_punishments) / distPop)) - 1\n",
    "        disparity = Decimal(disparity)\n",
    "        disparity = disparity.quantize(Decimal('0.01'))\n",
    "    return float(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def impossible(distPop, raceP, all_punishments, group_punishments):\n",
    "\n",
    "    \"\"\"\n",
    "    >>> print(impossible(50, 20, 20, 100))\n",
    "    1\n",
    "    >>> impossible(20, 0, 20, 0)\n",
    "    0\n",
    "    \"\"\"\n",
    "\n",
    "    # The \"RecordError\" column flags implausible data entries. Some of them could still be true if school administrators\n",
    "    # applied different standards different standards to determine which students belong to which demographic group.\n",
    "    # Or some could be the result of students not being counted because of the time they moved in and out of district.\n",
    "\n",
    "    if group_punishments > max(all_punishments,8): # eight because TEA could report 2 masked columns with 4 each\n",
    "        return 1\n",
    "    if raceP == 0 and group_punishments > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def getFisher(distPop, racePop, all_punishments, group_punishments):\n",
    "\n",
    "    \"\"\"\n",
    "    >>> getFisher(20, 5, 20, 10)\n",
    "    2\n",
    "    >>> getFisher(20, 0, 20, 0)\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # I don't know if this is a valid way to report the Fisher's exact test statistic, but the idea is that if getFisher returns a\n",
    "    # positive number over .95, there's a 95% chance that the group's better-than-average treatment is not due to chance.\n",
    "    # If it returns a number under -.95, there's a 95% chance that the group's worse-than-average treatment is not due to chance.\n",
    "    # I think it should be easier to create a color scale to show the scores on a map this way.\n",
    "\n",
    "    # The getFisher function assumes wrongly that everyone can have only one punishment (of each type). If the number of\n",
    "    # punishments exceeds the number of kids, it reduces the number of punishments (and assumes wrongly that every\n",
    "    # kid has been punished) But maybe the results are still close enough to correct to use for scaling?\n",
    "\n",
    "    \n",
    "    if max(racePop, group_punishments) == 0 or None:\n",
    "        return None\n",
    "    if distPop == 0:\n",
    "        return None\n",
    "    elif max(group_punishments, all_punishments) == 0 or None:\n",
    "        return 0\n",
    "    else:\n",
    "        try: \n",
    "            oddsratio, pvalueG = stats.fisher_exact([[racePop, max(distPop - racePop, 0)],\n",
    "                                                 [group_punishments, max(all_punishments - group_punishments, 0)]],\n",
    "                                                alternative='greater')\n",
    "        except ValueError:\n",
    "            print(distPop, racePop, all_punishments, group_punishments)\n",
    "        oddsratio, pvalueL = stats.fisher_exact([[racePop, max(distPop - racePop, 0)],\n",
    "                                                 [group_punishments, max(all_punishments - group_punishments, 0)]],\n",
    "                                                alternative='less')\n",
    "        if pvalueL < pvalueG:\n",
    "            pv = 1 - pvalueL\n",
    "        else:\n",
    "            pv = pvalueG - 1\n",
    "        \n",
    "        # To save space in the JSON, this simplifies the decimal values to an integer from -6 to 6\n",
    "        # It should replace similar code in txappleseedmap/js/index.js\n",
    "        \n",
    "        scale = -6\n",
    "        scale_colors = (-0.99999,-0.9984,-0.992,-0.96,-0.8,-0.2,0.2,0.8,0.96,0.992,0.9984,0.99999)\n",
    "        \n",
    "        for v in scale_colors:\n",
    "            if pv > v:\n",
    "                scale += 1\n",
    "        \n",
    "        # pv = Decimal(pv)\n",
    "        # pv = pv.quantize(Decimal('0.000001'))\n",
    "    return scale\n",
    "\n",
    "print(getFisher(20, 5, 20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../geojson/base_districts.geojson\") as json_data:\n",
    "    district_map = json.load(json_data)\n",
    "    json_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeIDs = set()\n",
    "\n",
    "for shape in district_map[\"features\"]:\n",
    "    shape[\"id\"] = shape[\"properties\"][\"DISTRICT_N\"]\n",
    "    assert shape[\"id\"] not in shapeIDs, \"id already in list: %r\" % shape[\"id\"]\n",
    "    shapeIDs.add(shape[\"id\"])\n",
    "    \n",
    "    # These two fields look redundant. Let's try deleting them.\n",
    "    \n",
    "    shape[\"properties\"].pop(\"DISTRICT_1\", None)\n",
    "    shape[\"properties\"].pop(\"OBJECTID_1\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(district_map[\"features\"][1]['geometry']['coordinates'][0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For districts overall, need columns that show what percentage of the state population they have\n",
    "# and what percentage of the punishments?\n",
    "\n",
    "def getLE(x, year_col):\n",
    "    \n",
    "    # Collects the correct values from the dataframes called \"apple\" and \"district\"\n",
    "    # and calls the \"impossible\" function, which looks for data errors\n",
    "    \n",
    "    distPop = x[\"DPETALLC\"]\n",
    "    if distPop in (0, None, np.nan):\n",
    "        return 1\n",
    "    elif x[\"HEADING NAME\"] == \"ALL\":\n",
    "        return 0\n",
    "    else:    \n",
    "        all_punishments = x[\"all_punishments\"]\n",
    "        # all_punishments = apple.loc[x[\"DISTRICT\"]][x[\"SECTION\"]][\"ALL\"]\n",
    "        group_punishments = x[year_col]\n",
    "        # trying to make this run faster by returning info for two columns, then splitting them\n",
    "        raceP = x[\"DPET{}P\".format(x[\"HEADING NAME\"][:3])]\n",
    "        return impossible(distPop, raceP, all_punishments, group_punishments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScale(x, year_col, punishment_totals, statewide_students_count):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function does something different for the \"HEADING NAME == ALL\" rows than for the other rows.\n",
    "    For the \"ALL\" rows it uses the whole state population as the \"distPop\" and uses the entire district population\n",
    "    as the \"racePop\". For the other rows, the entire district population is used as \"distPop\", not \"racePop\".\n",
    "    \n",
    "    And this function calls getFisher for the real calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    group_punishments = x[year_col]\n",
    "    if x[\"HEADING NAME\"] == \"ALL\":\n",
    "        distPop = statewide_students_count\n",
    "        racePop = x[\"DPETALLC\"]\n",
    "        all_punishments = punishment_totals[x[\"SECTION\"]]\n",
    "    else:\n",
    "        distPop = x[\"DPETALLC\"]\n",
    "        racePop = x[\"DPET{}P\".format(x[\"HEADING NAME\"])] * distPop * .01\n",
    "        if pd.isna(racePop):\n",
    "            return None\n",
    "        if pd.isnull(x[\"all_punishments\"]):\n",
    "            print(\"null all_punishments: \" + str(x))\n",
    "        all_punishments = x[\"all_punishments\"]\n",
    "    return getFisher(distPop, racePop, all_punishments, group_punishments)\n",
    "\n",
    "def getPercentage(x, year_col, punishment_totals):\n",
    "    if x[\"HEADING NAME\"] == \"ALL\":\n",
    "        return x[\"all_punishments\"] / punishment_totals[x[\"SECTION\"]] * 100\n",
    "    else:\n",
    "        return x[year_col] / x[\"all_punishments\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting year 2006\n",
      "       DISTRICT SECTION  all_punishments\n",
      "12970     31901     EXP               73\n",
      "12971     31901     DAE              826\n",
      "12972     31901     OSS             3144\n",
      "12973     31901     ISS            15309\n",
      "12974    108902     EXP               18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:128: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting year 2007\n",
      "       DISTRICT SECTION  all_punishments\n",
      "13039     31901     EXP              161\n",
      "13040     31901     DAE             1083\n",
      "13041     31901     OSS             3797\n",
      "13042     31901     ISS            16270\n",
      "13043    108902     EXP               13\n",
      "starting year 2008\n",
      "       DISTRICT SECTION  all_punishments\n",
      "13041     31901     EXP              167\n",
      "13042     31901     DAE              924\n",
      "13043     31901     OSS             4865\n",
      "13044     31901     ISS            12851\n",
      "13045    108902     EXP               25\n",
      "starting year 2009\n",
      "       DISTRICT SECTION  all_punishments\n",
      "12939     31901     EXP               56\n",
      "12940     31901     DAE              841\n",
      "12941     31901     OSS             4136\n",
      "12942     31901     ISS            13229\n",
      "12943    108902     EXP               28\n",
      "starting year 2010\n",
      "       DISTRICT SECTION  all_punishments\n",
      "13065     31901     EXP               58\n",
      "13066     31901     DAE              889\n",
      "13067     31901     OSS             4952\n",
      "13068     31901     ISS            16379\n",
      "13069    108902     EXP                2\n",
      "starting year 2011\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17536     31901     EXP               38\n",
      "17537     31901     DAE              936\n",
      "17538     31901     OSS             3468\n",
      "17539     31901     ISS            14647\n",
      "17540    108902     EXP               33\n",
      "starting year 2012\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17396     31901     EXP               51\n",
      "17397     31901     DAE              848\n",
      "17398     31901     OSS             3717\n",
      "17399     31901     ISS            14344\n",
      "17400    108902     EXP                2\n",
      "starting year 2013\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17576     31901     EXP                2\n",
      "17577     31901     DAE              647\n",
      "17578     31901     OSS             2950\n",
      "17579     31901     ISS            10534\n",
      "17580    108902     EXP               23\n",
      "starting year 2014\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17394     31901     EXP               38\n",
      "17395     31901     DAE              671\n",
      "17396     31901     OSS             2715\n",
      "17397     31901     ISS             8848\n",
      "17398    108902     EXP                2\n",
      "starting year 2015\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17234     31901     EXP               38\n",
      "17235     31901     DAE              711\n",
      "17236     31901     OSS             2647\n",
      "17237     31901     ISS             9500\n",
      "17238    108902     EXP                2\n",
      "starting year 2016\n",
      "       DISTRICT SECTION  all_punishments\n",
      "17141     31901     EXP                2\n",
      "17142     31901     DAE              602\n",
      "17143     31901     OSS             3091\n",
      "17144     31901     ISS             8413\n",
      "17145    108902     EXP                2\n"
     ]
    }
   ],
   "source": [
    "# Need to merge columns of apple and district.\n",
    "\n",
    "years = [x for x in range(first_year, last_year + 1)] # change back to first_year\n",
    "\n",
    "pop_stats = (\"DPETALLC\",\"DPETALLP\", \"DPETBLAP\",\"DPETHISP\",\"DPETWHIP\",\"DPETINDP\",\"DPETASIP\",\"DPETPCIP\",\n",
    "             \"DPETTWOP\",\"DPETECOP\",\"DPETSPEP\")\n",
    "\n",
    "demos = ('ALL','SPE', 'ECO','HIS','BLA', 'WHI','IND', 'ASI','PCI', 'TWO')\n",
    "\n",
    "punishments = ('EXP','DAE','OSS','ISS')\n",
    "\n",
    "fail = {} # for testing\n",
    "noScale = {}\n",
    "\n",
    "\n",
    "# Run again with the new changes and see how it works.\n",
    "\n",
    "manyDFs = []\n",
    "for year in years:\n",
    "    print(\"starting year \" + str(year))\n",
    "    manyDFs.append(getYear(year))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = pd.concat(manyDFs)\n",
    "\n",
    "apple.to_csv('../data/DistrictDisparitiesAll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-f3d52f1c47d3>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-f3d52f1c47d3>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for entry in district_map[\"features\"]:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# populating the GeoJSON file, which already has geometry for the districts.\n",
    "    # This previously was called in the loop for creating a single year of data, \n",
    "    # will need to be changed to apply it to all years at once.\n",
    "    \n",
    "    for entry in district_map[\"features\"]:\n",
    "        if entry[\"id\"] in district.index:\n",
    "            entry[\"properties\"][year] = {}\n",
    "            for stat in pop_stats:\n",
    "                # This will give NaN (numpy.float64) when empty\n",
    "                if pd.notnull(district.loc[entry[\"id\"]][stat]):\n",
    "                    try:\n",
    "                        entry[\"properties\"][year][stat] = district.loc[entry[\"id\"]][stat]\n",
    "                    except KeyError:\n",
    "                        # for when the map has a district not in the TEA's data\n",
    "                        print(\"no stats for \" + str(year) + \" \" + str(entry[\"id\"]))\n",
    "                        entry[\"properties\"][year][stat] = None\n",
    "        if entry[\"id\"] in apple.index.get_level_values(0):\n",
    "            for punishment in punishments:\n",
    "                entry[\"properties\"][year][punishment] = {}\n",
    "                for demo in demos:\n",
    "                    if (entry[\"id\"],punishment,demo) in apple.index:\n",
    "                    # if pd.notnull(apple.loc[entry[\"id\"],punishment,demo][year_col]): # should prevent empty dicts at \"demo\" level\n",
    "                        entry[\"properties\"][year][punishment][demo] = {} \n",
    "                        try:\n",
    "                            entry[\"properties\"][year][punishment][demo][\"C\"] = int(apple.loc[entry[\"id\"],punishment,demo][year_col])\n",
    "                            entry[\"properties\"][year][punishment][demo][\"E\"] = int(apple.loc[entry[\"id\"],punishment,demo][\"LikelyError\"])\n",
    "                            entry[\"properties\"][year][punishment][demo][\"%\"] = float(apple.loc[entry[\"id\"],punishment,demo][\"Percentage\"])\n",
    "                        except:\n",
    "                            fail[entry[\"id\"]] = (year,punishment,demo)\n",
    "                        try:\n",
    "                            entry[\"properties\"][year][punishment][demo][\"S\"] = int(apple.loc[entry[\"id\"],punishment,demo][\"Scale\"])\n",
    "                        except:\n",
    "                            noScale[entry[\"id\"]] = (year,punishment,demo)\n",
    "    print(district_map[\"features\"][30][\"properties\"])\n",
    "                    # print(\"Nothing for {} {} {}\".format(entry[\"id\"],punishment,demo))\n",
    "                    # impossible(distPop, racePop, all_punishments, group_punishments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notnull(district.loc[228905])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(apple.loc[entry[\"id\"],punishment,demo][year_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(apple.loc[entry[\"id\"],punishment,demo][\"Percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.loc[entry[\"id\"],punishment,demo][\"Scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../geojson/districts_with_data.geojson', 'w') as fp:\n",
    "    json.dump(district_map, fp, default=int)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "\n",
    "fc = geojson.FeatureCollection(district_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(geojson.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../geojson/districts_with_data.geojson\") as geo_data:\n",
    "    fc = geojson.load(geo_data)\n",
    "    geo_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "district_map[\"features\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if the file we produced is valid GeoJSON\n",
    "\n",
    "fc.is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district.loc[67908]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(noScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['A'] > 0]\n",
    "\n",
    "q = district_map[\"features\"][900][\"properties\"][\"DISTRICT_N\"]\n",
    "\n",
    "district.loc[q]\n",
    "\n",
    "# district[district[\"DISTRICT\"] == 167903]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
